{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-ddc0d1a376cc>, line 11)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-ddc0d1a376cc>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m       \n^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "class Genetic:\n",
    "    \"\"\" Wrapper class for deap genetic algorithms\n",
    "    \"\"\"\n",
    "    \n",
    "    def _init_(self, beginning_networks, data):\n",
    "    \"\"\" Initialize genetic class\n",
    "    \n",
    "        :param: self: current genetic class\n",
    "        :param: beginning_networks: first neural networks to start evolving\n",
    "        :param: data: array/list/data structure of useful replay data\n",
    "    \"\"\"\n",
    "        #our parameters\n",
    "        self.finalCount = 10\n",
    "            # How many individuals do we want in the end?\n",
    "        #weight domain (for mutations)\n",
    "        self.__weightMAX = 1.0\n",
    "        self.__weightMIN = 0.0\n",
    "        \n",
    "        #deap algorithm arguments\n",
    "        self.networks = beginning_networks\n",
    "        self.data = data\n",
    "        self.toolbox = Toolbox()\n",
    "        self.tournsize = 2\n",
    "            # number of parents selected from each generation\n",
    "        self.genSize = 10\n",
    "        self.cxpb = 1.0\n",
    "            # probability of mating two individuals\n",
    "        self.mutpb_indiv = 1.0\n",
    "            # probability of mutating an individual\n",
    "            # 1.0 because we want to maybe mutate a weight,\n",
    "                # not maybe mutate an entire individual.\n",
    "            # 1.0 means that no individual will be exempt\n",
    "                # from its weights being mutated.\n",
    "        self.mutpb_weight = 0.2\n",
    "            # probability of mutating a weight\n",
    "        self.ngen = 10000\n",
    "            # 10000 is probably far too low/high.\n",
    "                # I pulled it out of a hat.\n",
    "            # TODO see if there's a standard value or\n",
    "                # if we just need to do trial & error\n",
    "                # to balance time & performance.\n",
    "        \n",
    "    def begin(self, X, Y):\n",
    "    \"\"\" \n",
    "        Toolbox needs aliases: mate, mutate, select, evaluate\n",
    "        Data from replays passed in as param X and Y(see NN evaluate fitness)\n",
    "    \"\"\"\n",
    "        self.toolbox.register(\"mate\", ,)\n",
    "            #TODO write custom crossover function\n",
    "        self.toolbox.register(\"mutate\"\n",
    "            , mutate #defined below\n",
    "            , mutProb=self.mutpb_weight\n",
    "            , weightMIN=self.__weightMIN\n",
    "            , weightMAX=self.__weightMAX )\n",
    "        self.toolbox.register(\"select\"\n",
    "            , deap.tools.selTournament\n",
    "                #...(individuals, k, tournsize, fit_attr='fitness')\n",
    "            , k = self.genSize\n",
    "            , tournsize = self.tournsize\n",
    "            , fit_attr = 'fitness')\n",
    "        self.toolbox.register(\"evaluate\", evaluate, paramX = X, paramY = Y)\n",
    "        \n",
    "        population = self.networks\n",
    "        cxpb = self.cxpb\n",
    "            # probability of mating two individuals\n",
    "        mutpb = self.mutpb_indiv\n",
    "            # probability of mutating an individual\n",
    "        ngen = self.ngen\n",
    "        halloffame = deap.tools.HallOfFame( self.finalCount )\n",
    "            # Object that keeps track of the x best individuals.\n",
    "            # x = self.finalCount = number of individuals we want in the end\n",
    "        \n",
    "        deap.algorithms.eaSimple(population, self.toolbox, cxpb, mutpb, ngen, halloffame)\n",
    "        \n",
    "        return halloffame\n",
    "        \n",
    "def mutate( individual, mutProb, weightMIN, weightMAX ):\n",
    "\"\"\"\n",
    "    Mutates an individual, in-place.\n",
    "    For each weight, maybe assigns new value between\n",
    "         [ weightMIN, weightMAX ].\n",
    "    :param individual: the neural network to be mutated\n",
    "    :param mutProb: the probability of mutating a given weight\n",
    "    :param weightMIN: minimum value of a weight\n",
    "    :param weightMAX: maximum value of a weight\n",
    "\"\"\"\n",
    "    LAYERS = individual.get_num_layers()\n",
    "        # TODO I think I saw a bug in get_weights in network.py.\n",
    "        # Shouldn't an error be raised if layer >= self.num_layers\n",
    "        # not layer > self.num_layers?\n",
    "        # Jose is new to Python, so he could be wrong.\n",
    "        # If he's wrong, change LAYERS-1 to LAYERS.\n",
    "\n",
    "    #for all layers\n",
    "    for l in range( 0, LAYERS-1 ):\n",
    "\n",
    "        weights = individual.get_weights( l )\n",
    "        # numpy array copy of this layer's weights\n",
    "\n",
    "        #for all weights in this layer\n",
    "        for w in range( 0, len(weights) ):\n",
    "            if random.uniform(0,1) <= mutProb:\n",
    "                #randomize the weight\n",
    "            newWeights[w] = random.uniform( weightMIN, weightMAX )\n",
    "                    #TODO IMPORTANT\n",
    "                        # Jose doesn't know if we want integers\n",
    "                        # or floating points. Jose doesn't know\n",
    "                        # what the weight domain is.\n",
    "\n",
    "        individual.set_weights( l, weights )\n",
    "            # set weights for one layer\n",
    "    return\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    # Assuming both individuals have same number of layers?\n",
    "    # Crossing over an entire layer's weights since there is no way currently to get\n",
    "    # or set individual weights\n",
    "    \n",
    "    # randomize layer to cross over\n",
    "    num_layers = parent1.num_layers\n",
    "    crossoverLayer = randint(0, num_layers - 1)\n",
    "    \n",
    "    # crossover entire layer's weights\n",
    "    parent1_weights = parent1.get_weights(crossoverLayer)\n",
    "    parent1.set_weights(crossoverLayer, parent2.get_weights(crossoverLayer))\n",
    "    parent2.set_weights(crossoverLayer, parent1_weights)\n",
    "    \n",
    "    return parent1, parent2\n",
    "        \n",
    "def evaluate(individual, paramX, paramY):\n",
    "    return evaluateFitness(individual, paramX, paramY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
